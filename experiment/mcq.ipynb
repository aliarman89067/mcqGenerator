{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms.octoai_endpoint import OctoAIEndpoint\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEY = os.environ[\"OCTOAI_API_TOKEN\"]\n",
    "os.environ[\"ENDPOINT_URL\"] = \"https://text.octoai.run/v1/chat/completions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OctoAIEndpoint(\n",
    "    model_kwargs={\n",
    "        \"model\": \"llama-2-13b-chat-fp16\",\n",
    "        \"max_tokens\": 128,\n",
    "        \"presence_penalty\": 0,\n",
    "        \"temperature\": 0.5,\n",
    "        \"top_p\": 0.9,\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant. Keep your responses limited to one short paragraph if possible.\",\n",
    "            },\n",
    "        ],\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import octoai_endpoint\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains import SequentialChain\n",
    "from langchain.callbacks import get_openai_callback\n",
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESPONSE_JSON = {\n",
    "    \"1\":{\n",
    "        \"mcq\":\"Multiple choice question\",\n",
    "        \"options\":{\n",
    "            \"a\":\"Choice here\",\n",
    "            \"b\":\"Choice here\",\n",
    "            \"c\":\"Choice here\",\n",
    "            \"d\":\"Choice here\",\n",
    "        },\n",
    "        \"correct answer\":\"Correct Answer\"\n",
    "    },\n",
    "    \"2\":{\n",
    "        \"mcq\":\"Multiple choice question\",\n",
    "        \"options\":{\n",
    "            \"a\":\"Choice here\",\n",
    "            \"b\":\"Choice here\",\n",
    "            \"c\":\"Choice here\",\n",
    "            \"d\":\"Choice here\",\n",
    "        },\n",
    "        \"correct answer\":\"Correct Answer\"\n",
    "    },\n",
    "    \"3\":{\n",
    "        \"mcq\":\"Multiple choice question\",\n",
    "        \"options\":{\n",
    "            \"a\":\"Choice here\",\n",
    "            \"b\":\"Choice here\",\n",
    "            \"c\":\"Choice here\",\n",
    "            \"d\":\"Choice here\",\n",
    "        },\n",
    "        \"correct answer\":\"Correct Answer\"\n",
    "    },\n",
    "    \"4\":{\n",
    "        \"mcq\":\"Multiple choice question\",\n",
    "        \"options\":{\n",
    "            \"a\":\"Choice here\",\n",
    "            \"b\":\"Choice here\",\n",
    "            \"c\":\"Choice here\",\n",
    "            \"d\":\"Choice here\",\n",
    "        },\n",
    "        \"correct answer\":\"Correct Answer\"\n",
    "    },\n",
    "    \"5\":{\n",
    "        \"mcq\":\"Multiple choice question\",\n",
    "        \"options\":{\n",
    "            \"a\":\"Choice here\",\n",
    "            \"b\":\"Choice here\",\n",
    "            \"c\":\"Choice here\",\n",
    "            \"d\":\"Choice here\",\n",
    "        },\n",
    "        \"correct answer\":\"Correct Answer\"\n",
    "    },\n",
    "    \"6\":{\n",
    "        \"mcq\":\"Multiple choice question\",\n",
    "        \"options\":{\n",
    "            \"a\":\"Choice here\",\n",
    "            \"b\":\"Choice here\",\n",
    "            \"c\":\"Choice here\",\n",
    "            \"d\":\"Choice here\",\n",
    "        },\n",
    "        \"correct answer\":\"Correct Answer\"\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE=\"\"\"\n",
    "Text:{text}\n",
    "You are an expert MCQ maker. Given the above text is your job to\n",
    "create a quiz of {number} multiple choice questions for {subject} student in an tone of {tone}\n",
    "make sure that question is not repeating and check all the question confirming the text as well\n",
    "make sure format your response like RESPONSE_JSON and use it as a guide.\n",
    "Ensure to make {number} MCQS\n",
    "###RESPONSE_JSON\n",
    "{response_json}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_generator_prompt = PromptTemplate(\n",
    "    input_variables=[\"text\",\"number\",\"subject\",\"tone\",\"response_json\"],\n",
    "    template=TEMPLATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_chain=LLMChain(llm=llm, prompt=quiz_generator_prompt, output_key=\"quiz\" ,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE2=\"\"\"\n",
    "You are an expert english grammarian and writer. Given a multiple choice quiz for {subject} students\n",
    "you need to evalute the complexity of the question and give a complete analysis of the quiz. Only use at max 50 words for the complexity\n",
    "if the quiz is not at per cognitive and analytical ablilities of the students,\n",
    "update the quiz questions which needs to be changed and change the tone that it perfectly fits the student abilities\n",
    "Quiz_Mcqs\n",
    "{quiz}\n",
    "\n",
    "Check from the expert english writer from the above quiz\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_evaluation_prompt=PromptTemplate(\n",
    "    input_variables=[\"subject\", \"quiz\"],\n",
    "    template=TEMPLATE2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_chain=LLMChain(llm=llm, prompt=quiz_evaluation_prompt, output_key=\"review\" ,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_evaluate_chain=SequentialChain(chains=[quiz_chain, review_chain], verbose=True, input_variables=[\"text\",\"number\",\"subject\",\"tone\",\"response_json\"], output_variables=[\"quiz\",\"review\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path=r\"D:\\python\\mcqGenerator\\data.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_path,'r') as file:\n",
    "    Text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"1\": {\"mcq\": \"Multiple choice question\", \"options\": {\"a\": \"Choice here\", \"b\": \"Choice here\", \"c\": \"Choice here\", \"d\": \"Choice here\"}, \"correct answer\": \"Correct Answer\"}, \"2\": {\"mcq\": \"Multiple choice question\", \"options\": {\"a\": \"Choice here\", \"b\": \"Choice here\", \"c\": \"Choice here\", \"d\": \"Choice here\"}, \"correct answer\": \"Correct Answer\"}, \"3\": {\"mcq\": \"Multiple choice question\", \"options\": {\"a\": \"Choice here\", \"b\": \"Choice here\", \"c\": \"Choice here\", \"d\": \"Choice here\"}, \"correct answer\": \"Correct Answer\"}, \"4\": {\"mcq\": \"Multiple choice question\", \"options\": {\"a\": \"Choice here\", \"b\": \"Choice here\", \"c\": \"Choice here\", \"d\": \"Choice here\"}, \"correct answer\": \"Correct Answer\"}, \"5\": {\"mcq\": \"Multiple choice question\", \"options\": {\"a\": \"Choice here\", \"b\": \"Choice here\", \"c\": \"Choice here\", \"d\": \"Choice here\"}, \"correct answer\": \"Correct Answer\"}, \"6\": {\"mcq\": \"Multiple choice question\", \"options\": {\"a\": \"Choice here\", \"b\": \"Choice here\", \"c\": \"Choice here\", \"d\": \"Choice here\"}, \"correct answer\": \"Correct Answer\"}}'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.dumps(RESPONSE_JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_variables = {\n",
    "    \"text\": \"What do you think about SEO\",\n",
    "    \"number\": 4,\n",
    "    \"subject\": \"Artificial Intelligence\",\n",
    "    \"tone\": \"Simple\",\n",
    "    \"response_json\":RESPONSE_JSON\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Text:What do you think about SEO\n",
      "You are an expert MCQ maker. Given the above text is your job to\n",
      "create a quiz of 4 multiple choice questions for Artificial Intelligence student in an tone of Simple\n",
      "make sure that question is not repeating and check all the question confirming the text as well\n",
      "make sure format your response like RESPONSE_JSON and use it as a guide.\n",
      "Ensure to make 4 MCQS\n",
      "###RESPONSE_JSON\n",
      "{'1': {'mcq': 'Multiple choice question', 'options': {'a': 'Choice here', 'b': 'Choice here', 'c': 'Choice here', 'd': 'Choice here'}, 'correct answer': 'Correct Answer'}, '2': {'mcq': 'Multiple choice question', 'options': {'a': 'Choice here', 'b': 'Choice here', 'c': 'Choice here', 'd': 'Choice here'}, 'correct answer': 'Correct Answer'}, '3': {'mcq': 'Multiple choice question', 'options': {'a': 'Choice here', 'b': 'Choice here', 'c': 'Choice here', 'd': 'Choice here'}, 'correct answer': 'Correct Answer'}, '4': {'mcq': 'Multiple choice question', 'options': {'a': 'Choice here', 'b': 'Choice here', 'c': 'Choice here', 'd': 'Choice here'}, 'correct answer': 'Correct Answer'}, '5': {'mcq': 'Multiple choice question', 'options': {'a': 'Choice here', 'b': 'Choice here', 'c': 'Choice here', 'd': 'Choice here'}, 'correct answer': 'Correct Answer'}, '6': {'mcq': 'Multiple choice question', 'options': {'a': 'Choice here', 'b': 'Choice here', 'c': 'Choice here', 'd': 'Choice here'}, 'correct answer': 'Correct Answer'}}\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "  Sure, I'd be happy to help! Here are four multiple choice questions based on the text \"What do you think about SEO?\"\n",
      "\n",
      "1. What is the primary focus of SEO?\n",
      "a) Creating high-quality content\n",
      "b) Building backlinks from other websites\n",
      "c) Optimizing website structure and design\n",
      "d) All of the above\n",
      "\n",
      "Correct answer: d) All of the above\n",
      "\n",
      "2. Which of the following is NOT a factor that search engines use to rank websites?\n",
      "a) Keyword usage in the content\n",
      "b) Relevance of the content to\n"
     ]
    }
   ],
   "source": [
    "result = quiz_chain.run(input_variables)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 3 (char 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[87], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\python\\mcqGenerator\\env\\Lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[1;32md:\\python\\mcqGenerator\\env\\Lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[1;32md:\\python\\mcqGenerator\\env\\Lib\\json\\decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 3 (char 2)"
     ]
    }
   ],
   "source": [
    "json.loads(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
